{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read Data From CSV Files **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_full_name(path_to_csv, path_to_new_csv):\n",
    "    #Assume you will be reading in a csv file with the same columns that the\n",
    "    #Lahman baseball data set has -- most importantly, there are columns\n",
    "    #called 'nameFirst' and 'nameLast'.\n",
    "    #1) Write a function that reads a csv\n",
    "    #located at \"path_to_csv\" into a pandas dataframe and adds a new column\n",
    "    #called 'nameFull' with a player's full name.\n",
    "    #\n",
    "    #For example:\n",
    "    #   for Hank Aaron, nameFull would be 'Hank Aaron', \n",
    "\t#\n",
    "\t#2) Write the data in the pandas dataFrame to a new csv file located at\n",
    "\t#path_to_new_csv\n",
    "\n",
    "    #WRITE YOUR CODE HERE\n",
    "    df_original = pd.read_csv(path_to_csv)\n",
    "    df_original['nameFull'] = df_original['nameFirst']+\" \" + df_original['nameLast']\n",
    "    df_original.to_csv(path_to_new_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use only\n",
    "    # If you are running this on your own machine add the path to the\n",
    "    # Lahman baseball csv and a path for the new csv.\n",
    "    # The dataset can be downloaded from this website: http://www.seanlahman.com/baseball-archive/statistics\n",
    "    # We are using the file Master.csv\n",
    "    path_to_csv = \"Master.csv\"\n",
    "    path_to_new_csv = \"Master_New.csv\"\n",
    "    add_full_name(path_to_csv, path_to_new_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read the Data from Database **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def select_first_50(filename):\n",
    "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
    "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
    "    # column names more closely resemble columns names one might find in a table.\n",
    "    aadhaar_data = pandas.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "    # Select out the first 50 values for \"registrar\" and \"enrolment_agency\"\n",
    "    # in the aadhaar_data table using SQL syntax. \n",
    "    #\n",
    "    # Note that \"enrolment_agency\" is spelled with one l. Also, the order\n",
    "    # of the select does matter. Make sure you select registrar then enrolment agency\n",
    "    # in your query.\n",
    "    #\n",
    "    # You can download a copy of the aadhaar data that we are passing \n",
    "    # into this exercise below:\n",
    "    # https://www.dropbox.com/s/vn8t4uulbsfmalo/aadhaar_data.csv\n",
    "    q = \"\"\"\n",
    "    -- YOUR QUERY HERE\n",
    "    \"\"\"\n",
    "    q = \"SELECT registrar,  enrolment_agency FROM aadhaar_data LIMIT 50\"\n",
    "    #Execute your SQL command against the pandas frame\n",
    "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
    "    return aadhaar_solution    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def aggregate_query(filename):\n",
    "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
    "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
    "    # column names more closely resemble columns names one might find in a table.\n",
    "    \n",
    "    aadhaar_data = pandas.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "    # Write a query that will select from the aadhaar_data table how many men and how \n",
    "    # many women over the age of 50 have had aadhaar generated for them in each district.\n",
    "    # aadhaar_generated is a column in the Aadhaar Data that denotes the number who have had\n",
    "    # aadhaar generated in each row of the table.\n",
    "    #\n",
    "    # Note that in this quiz, the SQL query keywords are case sensitive. \n",
    "    # For example, if you want to do a sumpath_to_csv = \"Master.csv\" make sure you type 'sum' rather than 'SUM'.\n",
    "    #\n",
    "\n",
    "    # The possible columns to select from aadhaar data are:\n",
    "    #     1) registrar\n",
    "    #     2) enrolment_agency\n",
    "    #     3) state\n",
    "    #     4) district\n",
    "    #     5) sub_district\n",
    "    #     6) pin_code\n",
    "    #     7) gender\n",
    "    #     8) age\n",
    "    #     9) aadhaar_generated\n",
    "    #     10) enrolment_rejected\n",
    "    #     11) residents_providing_email,\n",
    "    #     12) residents_providing_mobile_number\n",
    "    #\n",
    "    # You can download a copy of the aadhaar data that we are passing \n",
    "    # into this exercise below:\n",
    "    # https://www.dropbox.com/s/vn8t4uulbsfmalo/aadhaar_data.csv\n",
    "    \n",
    "    q = \"SELECT gender, district, sum(aadhaar_generated) FROM aadhaar_data WHERE age>50 group by gender, district\"\n",
    "\n",
    "    # Execute your SQL command against the pandas frame\n",
    "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
    "    return aadhaar_solution    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read the Data from API,s **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'David Bowie'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "url = \"http://ws.audioscrobbler.com/2.0/?method=geo.getTopArtists&country=spain&api_key=958fd36c54910fa7ffd2627c4ce2c504&format=json\"\n",
    "def api_get_request(url):\n",
    "    # In this exercise, you want to call the last.fm API to get a list of the\n",
    "    # top artists in Spain. The grader will supply the URL as an argument to\n",
    "    # the function; you do not need to construct the address or call this\n",
    "    # function in your grader submission.\n",
    "    # \n",
    "    # Once you've done this, return the name of the number 1 top artist in\n",
    "    # Spain. \n",
    "    \n",
    "    data = requests.get(url).text\n",
    "    data = json.loads(data)\n",
    "    return data['topartists']['artist'][0]['name']\n",
    "\n",
    "api_get_request(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data Imputation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "def imputation(filename):\n",
    "    # Pandas dataframes have a method called 'fillna(value)', such that you can\n",
    "    # pass in a single value to replace any NAs in a dataframe or series. You\n",
    "    # can call it like this: \n",
    "    #     dataframe['column'] = dataframe['column'].fillna(value)\n",
    "    #\n",
    "    # Using the numpy.mean function, which calculates the mean of a numpy\n",
    "    # array, impute any missing values in our Lahman baseball\n",
    "    # data sets 'weight' column by setting them equal to the average weight.\n",
    "    # \n",
    "    # You can access the 'weight' colum in the baseball data frame by\n",
    "    # calling baseball['weight']\n",
    "\n",
    "    baseball = pandas.read_csv(filename)\n",
    "    \n",
    "    #YOUR CODE GOES HERE\n",
    "    mean_missing = baseball['weight'].dropna().mean()\n",
    "    baseball['weight'] = baseball['weight'].fillna(mean_missing)\n",
    "\n",
    "    return baseball\n",
    "\n",
    "filename = \"Master.csv\"\n",
    "#imputation(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_rainy_days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(rain)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(rain)\n",
       "0           10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def num_rainy_days(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - a count of the number of days in the dataframe where\n",
    "    the rain column is equal to 1 (i.e., the number of days it\n",
    "    rained).  The dataframe will be titled 'weather_data'. You'll\n",
    "    need to provide the SQL query.  You might find SQL's count function\n",
    "    useful for this exercise.  You can read more about it here:\n",
    "    \n",
    "    https://dev.mysql.com/doc/refman/5.1/en/counting-rows.html\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    your query here\n",
    "    \"\"\"\n",
    "    q = \"SELECT count(rain) from weather_data where rain=1\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days\n",
    "\n",
    "filename = \"weather_underground.csv\"\n",
    "num_rainy_days(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**max_temp_aggregate_by_fog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fog</th>\n",
       "      <th>max(maxtempi)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fog  max(maxtempi)\n",
       "0    0             86\n",
       "1    1             81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "\n",
    "def max_temp_aggregate_by_fog(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return two columns and\n",
    "    two rows - whether it was foggy or not (0 or 1) and the max\n",
    "    maxtempi for that fog value (i.e., the maximum max temperature\n",
    "    for both foggy and non-foggy days).  The dataframe will be \n",
    "    titled 'weather_data'. You'll need to provide the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    your query here\n",
    "    \"\"\"\n",
    "    q = 'SELECT fog, max(maxtempi) from weather_data group by fog'\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days\n",
    "\n",
    "\n",
    "filename = \"weather_underground.csv\"\n",
    "max_temp_aggregate_by_fog(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** avg_weekend_temperature **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(cast(meantempi as integer))\n",
      "0                        65.111111\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "from datetime import datetime, date\n",
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - the average meantempi on days that are a Saturday\n",
    "    or Sunday (i.e., the the average mean temperature on weekends).\n",
    "    The dataframe will be titled 'weather_data' and you can access\n",
    "    the date in the dataframe via the 'date' column.\n",
    "    \n",
    "    You'll need to provide  the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    Also, you can convert dates to days of the week via the 'strftime' keyword in SQL.\n",
    "    For example, cast (strftime('%w', date) as integer) will return 0 if the date\n",
    "    is a Sunday or 6 if the date is a Saturday.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "    weather_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "    \n",
    "    q = \"\"\"\n",
    "    SELECT AVG(cast(meantempi as integer))\n",
    "    FROM weather_data \n",
    "    WHERE cast(strftime('%w', date) as integer) in (0, 6)\"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    \n",
    "    return mean_temp_weekends\n",
    "\n",
    "filename = \"weather_underground.csv\"\n",
    "print avg_weekend_temperature(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**avg_min_temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(cast (mintempi as integer))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(cast (mintempi as integer))\n",
       "0                            61.25"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def avg_min_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data. More specifically you want to find the average\n",
    "    minimum temperature (mintempi column of the weather dataframe) on \n",
    "    rainy days where the minimum temperature is greater than 55 degrees.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT avg(cast (mintempi as integer)) FROM weather_data WHERE mintempi > 55\n",
    "    AND rain =1\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "filename = \"weather_underground.csv\"\n",
    "avg_min_temperature(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fix_turnstile_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def fix_turnstile_data(filenames):\n",
    "    '''\n",
    "    Filenames is a list of MTA Subway turnstile text files. A link to an example\n",
    "    MTA Subway turnstile text file can be seen at the URL below:\n",
    "    http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt\n",
    "    \n",
    "    As you can see, there are numerous data points included in each row of the\n",
    "    a MTA Subway turnstile text file. \n",
    "\n",
    "    You want to write a function that will update each row in the text\n",
    "    file so there is only one entry per row. A few examples below:\n",
    "    A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
    "    A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
    "    A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
    "    \n",
    "    Write the updates to a different text file in the format of \"updated_\" + filename.\n",
    "    For example:\n",
    "        1) if you read in a text file called \"turnstile_110521.txt\"\n",
    "        2) you should write the updated data to \"updated_turnstile_110521.txt\"\n",
    "\n",
    "    The order of the fields should be preserved. Remember to read through the \n",
    "    Instructor Notes below for more details on the task. \n",
    "    \n",
    "    In addition, here is a CSV reader/writer introductory tutorial:\n",
    "    http://goo.gl/HBbvyy\n",
    "    \n",
    "    You can see a sample of the turnstile text file that's passed into this function\n",
    "    and the the corresponding updated file in the links below:\n",
    "    \n",
    "    Sample input file:\n",
    "    https://www.dropbox.com/s/mpin5zv4hgrx244/turnstile_110528.txt\n",
    "    Sample updated file:\n",
    "    https://www.dropbox.com/s/074xbgio4c39b7h/solution_turnstile_110528.txt\n",
    "    '''\n",
    "    for one_file in filenames:\n",
    "\n",
    "        with open(one_file, \"r\") as read_data:\n",
    "            # Get rid of extra blank line.\n",
    "            # Open outfile with mode 'wb' instead of 'w'.\n",
    "            # The csv.writer writes \\r\\n into the file directly.\n",
    "            # If you don't open the file in binary mode,\n",
    "            # it will write \\r\\r\\n because on Windows text mode will translate each \\n into \\r\\n.\n",
    "            with open(\"updated_{}\".format(one_file), \"wb\") as write_data:\n",
    "                reader = csv.reader(read_data)\n",
    "                writer = csv.writer(write_data)\n",
    "                for line in reader:\n",
    "                    header = line[:3]\n",
    "                    clean_line = [s.strip() for s in line]\n",
    "                    rest = [clean_line[i:i+5] for i in range(3, len(clean_line), 5)]\n",
    "\n",
    "                    for each_one in rest:\n",
    "                        writer.writerow(header + each_one)\n",
    "            write_data.close()\n",
    "        read_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_master_turnstile_file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    '''\n",
    "    Write a function that takes the files in the list filenames, which all have the \n",
    "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
    "    them into one file located at output_file.  There should be ONE row with the column\n",
    "    headers, located at the top of the file. The input files do not have column header\n",
    "    rows of their own.\n",
    "    \n",
    "    For example, if file_1 has:\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    \n",
    "    and another file, file_2 has:\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    \n",
    "    We need to combine file_1 and file_2 into a master_file like below:\n",
    "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    '''\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            with open(filename, \"r\") as read_file:\n",
    "                for line in read_file:\n",
    "                    master_file.write(line) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filter_by_regular**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    \n",
    "    For example, if the pandas dataframe is as follows:\n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "    \n",
    "    The dataframe will look like below after filtering to only rows where DESCn column\n",
    "    has the value 'REGULAR':\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    '''\n",
    "    \n",
    "    turnstile_data = pandas.read_csv(filename)\n",
    "    # more of your code here\n",
    "    turnstile_data = turnstile_data[turnstile_data.DESCn == 'REGULAR']\n",
    "    return turnstile_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_hourly_entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative entry numbers to a count of entries since the last reading\n",
    "    (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called ENTRIESn_hourly\n",
    "       2) Assign to the column the difference between ENTRIESn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Examples of what your dataframe should look like at the end of this exercise:\n",
    "    \n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    '''\n",
    "    #your code here\n",
    "    df['ENTRIESn_hourly'] = df['ENTRIESn'] - df['ENTRIESn'].shift()\n",
    "    df.ENTRIESn_hourly.replace(np.nan, 1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_hourly_exits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def get_hourly_exits(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative exit numbers to a count of exits since the last reading\n",
    "    (i.e., exits since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called EXITSn_hourly\n",
    "       2) Assign to the column the difference between EXITSn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 0.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Example dataframe below:\n",
    "\n",
    "          Unnamed: 0   C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly  EXITSn_hourly\n",
    "    0              0  A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                0              0\n",
    "    1              1  A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23              8\n",
    "    2              2  A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18             18\n",
    "    3              3  A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71             54\n",
    "    4              4  A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170             44\n",
    "    5              5  A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214             42\n",
    "    6              6  A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87             11\n",
    "    7              7  A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10              3\n",
    "    8              8  A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36             89\n",
    "    9              9  A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153            333\n",
    "    '''\n",
    "    \n",
    "    #your code here\n",
    "    df['EXITSn_hourly'] = df['EXITSn'] - df['EXITSn'].shift()\n",
    "    df.EXITSn_hourly.replace('NaN', 0, inplace = True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**time_to_hour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def time_to_hour(time):\n",
    "    '''\n",
    "    Given an input variable time that represents time in the format of:\n",
    "    \"00:00:00\" (hour:minutes:seconds)\n",
    "    \n",
    "    Write a function to extract the hour part from the input variable time\n",
    "    and return it as an integer. For example:\n",
    "        1) if hour is 00, your code should return 0\n",
    "        2) if hour is 01, your code should return 1\n",
    "        3) if hour is 21, your code should return 21\n",
    "        \n",
    "    Please return hour as an integer.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    hour = hour = int(time[:2])# your code here\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reformat_subway_dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def reformat_subway_dates(date):\n",
    "    '''\n",
    "    The dates in our subway data are formatted in the format month-day-year.\n",
    "    The dates in our weather underground data are formatted year-month-day.\n",
    "    \n",
    "    In order to join these two data sets together, we'll want the dates formatted\n",
    "    the same way.  Write a function that takes as its input a date in the MTA Subway\n",
    "    data format, and returns a date in the weather underground format.\n",
    "    \n",
    "    Hint: \n",
    "    There are a couple of useful functions in the datetime library that will\n",
    "    help on this assignment, called strptime and strftime. \n",
    "    More info can be seen here and further in the documentation section:\n",
    "    http://docs.python.org/2/library/datetime.html#datetime.datetime.strptime\n",
    "    '''\n",
    "\n",
    "    date_formatted = datetime.datetime.strptime(date, \"%m-%d-%y\").strftime(\"%Y-%m-%d\")\n",
    "    return date_formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
